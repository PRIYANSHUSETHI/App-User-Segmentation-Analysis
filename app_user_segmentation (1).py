# -*- coding: utf-8 -*-
"""APP USER SEGMENTATION.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eFXNKtjIC-I3RivBnpLAS0Ba9xvWPhg9
"""

import plotly.graph_objects as go
import plotly.express as px
import plotly.io as pio
import pandas as pd
pio.templates.default = "plotly_white"

data = pd.read_csv("userbehaviour.csv")
print(data.head())

print(f'Average Screen Time = {data["Average Screen Time"].mean()}')
print(f'Highest Screen Time = {data["Average Screen Time"].max()}')
print(f'Lowest Screen Time = {data["Average Screen Time"].min()}')

print(f'Average Spend of the Users = {data["Average Spent on App (INR)"].mean()}')
print(f'Highest Spend of the Users = {data["Average Spent on App (INR)"].max()}')
print(f'Lowest Spend of the Users = {data["Average Spent on App (INR)"].min()}')

figure = px.scatter(data_frame = data,
                    x="Average Screen Time",
                    y="Average Spent on App (INR)",
                    size="Average Spent on App (INR)",
                    color= "Status",
                    title = "Relationship Between Spending Capacity and Screentime",
                    trendline="ols")
figure.show()

"""So this is great! Users who uninstalled the app had an average screen time of fewer than 5 minutes a day, and the average spent was less than 100. We can also see a linear relationship between the average screen time and the average spending of the users still using the app."""

figure = px.scatter(data_frame = data,
                    x="Average Screen Time",
                    y="Ratings",
                    size="Ratings",
                    color= "Status",
                    title = "Relationship Between Ratings and Screentime",
                    trendline="ols")
figure.show()

"""So we can see that users who uninstalled the app gave the app a maximum of five ratings. Their screen time is very low compared to users who rated more. So, this describes that users who donâ€™t like to spend more time rate the app low and uninstall it at some point.

**App User Segmentation to Find Retained and Lost Users**
"""

clustering_data = data[["Average Screen Time", "Left Review",
                        "Ratings", "Last Visited Minutes",
                        "Average Spent on App (INR)",
                        "New Password Request"]]

from sklearn.preprocessing import MinMaxScaler
for i in clustering_data.columns:
    MinMaxScaler(i)

from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=3)
clusters = kmeans.fit_predict(clustering_data)
data["Segments"] = clusters

print(data.head(10))

print(data["Segments"].value_counts())

data["Segments"] = data["Segments"].map({0: "Retained", 1:
    "Churn", 2: "Needs Attention"})

PLOT = go.Figure()
for i in list(data["Segments"].unique()):


    PLOT.add_trace(go.Scatter(x = data[data["Segments"]== i]['Last Visited Minutes'],
                                y = data[data["Segments"] == i]['Average Spent on App (INR)'],
                                mode = 'markers',marker_size = 6, marker_line_width = 1,
                                name = str(i)))
PLOT.update_traces(hovertemplate='Last Visited Minutes: %{x} <br>Average Spent on App (INR): %{y}')


PLOT.update_layout(width = 800, height = 800, autosize = True, showlegend = True,
                   yaxis_title = 'Average Spent on App (INR)',
                   xaxis_title = 'Last Visited Minutes',
                   scene = dict(xaxis=dict(title = 'Last Visited Minutes', titlefont_color = 'black'),
                                yaxis=dict(title = 'Average Spent on App (INR)', titlefont_color = 'black')))

"""The blue segment shows the segment of users the app has retained over time. The red segment indicates the segment of users who just uninstalled the app or are about to uninstall it soon. And the green segment indicates the segment of users that the application has lost."""

import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from sklearn.preprocessing import MinMaxScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import numpy as np  # Import numpy for handling infinite values

# --- Feature Engineering ---
data["Spending per Minute"] = data["Average Spent on App (INR)"] / data["Average Screen Time"]
data["Time Since Last Visit"] = data["Last Visited Minutes"].max() - data["Last Visited Minutes"]

# --- EDA (Quick Stats) ---
print(f"Average Screen Time: {data['Average Screen Time'].mean():.2f} mins")
print(f"Average Spend: â‚¹{data['Average Spent on App (INR)'].mean():.2f}")
print(f"Average Ratings: {data['Ratings'].mean():.2f}")

# --- Clustering ---
clustering_features = ["Average Screen Time", "Left Review", "Ratings",
                       "Last Visited Minutes", "Average Spent on App (INR)",
                       "New Password Request", "Spending per Minute"]

# --- Replace infinite values with NaN ---
data[clustering_features] = data[clustering_features].replace([np.inf, -np.inf], np.nan)

# --- Impute or remove NaN values ---
# Option 1: Remove rows with NaN values
# data.dropna(subset=clustering_features, inplace=True)

# Option 2: Impute NaN values with the mean of the column (or other imputation strategies)
for feature in clustering_features:
    data[feature].fillna(data[feature].mean(), inplace=True) # Impute NaN with mean


scaler = MinMaxScaler()
scaled_data = pd.DataFrame(scaler.fit_transform(data[clustering_features]), columns=clustering_features)

# --- Elbow Method ---
distortions = []
scores = []
K = range(2, 6)
for k in K:
    model = KMeans(n_clusters=k, random_state=42)
    model.fit(scaled_data)
    distortions.append(model.inertia_)
    scores.append(silhouette_score(scaled_data, model.labels_))

# Plot Elbow & Silhouette
px.line(x=list(K), y=distortions, markers=True, title="Elbow Method - Inertia vs K").show()
px.line(x=list(K), y=scores, markers=True, title="Silhouette Score vs K").show()

# --- Final Clustering ---
kmeans = KMeans(n_clusters=3, random_state=42)
data["Segment"] = kmeans.fit_predict(scaled_data)

# --- Dynamic Segment Naming ---
segment_profiles = data.groupby("Segment")[["Average Spent on App (INR)", "Ratings", "Average Screen Time"]].mean()
segment_order = segment_profiles.sort_values("Average Spent on App (INR)", ascending=False).index.tolist()

segment_names = {segment_order[0]: "ðŸ’Ž Loyal Spenders",
                 segment_order[1]: "ðŸš¶ Wanderers",
                 segment_order[2]: "ðŸ§Š Silent Churners"}

data["Segment Label"] = data["Segment"].map(segment_names)

# --- Cluster Visualization ---
PLOT = go.Figure()
for label in data["Segment Label"].unique():
    subset = data[data["Segment Label"] == label]
    PLOT.add_trace(go.Scatter(
        x=subset["Last Visited Minutes"],
        y=subset["Average Spent on App (INR)"],
        mode="markers",
        name=label,
        marker=dict(size=8, line=dict(width=1))
    ))

PLOT.update_layout(
    title="User Segments Based on Spending & Visit Behavior",
    xaxis_title="Last Visited Minutes",
    yaxis_title="Average Spent on App (INR)",
    width=900, height=600
)
PLOT.show()

# --- Recommendations for Each Segment ---
recommendations = {
    "ðŸ’Ž Loyal Spenders": "Reward them with exclusive perks and loyalty points.",
    "ðŸš¶ Wanderers": "Send re-engagement emails, push reminders, or in-app messages.",
    "ðŸ§Š Silent Churners": "Trigger retention campaigns before drop-off, offer onboarding guides."
}

print("\n=== Segment-Based Recommendations ===")
for label in segment_names.values():
    print(f"{label}: {recommendations[label]}")